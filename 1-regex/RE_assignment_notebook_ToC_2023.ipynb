{"cells":[{"cell_type":"markdown","metadata":{"id":"4gHPcg59zjr6"},"source":["Theory of Computation 2023 - Horacio Saggion\n","\n","Deliverable Regular Expressions\n","\n","\n","Please indicate the full names and NIAs of the team members as well as the team number\n","\n","TEAM: 10\n","\n","MEMBERS:\n","\n","\t(253885) - Luca Franceschi\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGcudUS8K4Jl"},"outputs":[],"source":["# If using Colaborate then allow Google to use your data files\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YA1x6iboL-8o"},"outputs":[],"source":["#cd to the directory in drive you will use (change to your shared folder)\n","%cd /content/drive/Shareddrives/ToC-2023/DELIVS/DELIV-1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zqQQX_DMHx3"},"outputs":[],"source":["# reading some data using the pandas library\n","import pandas as pd\n","\n","# my_data=pd.read_csv('DATA/ToC_2023_REs.csv', sep=',')\n","my_data=pd.read_csv('ToC_2023_REs.csv', sep=',')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrZLazXSMs-r"},"outputs":[],"source":["# the data is from twitter so it will contain interesting content\n","# we only need the column 'text' to work with\n","twitter_data=my_data['text']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qgurvr6NA7W"},"outputs":[],"source":["# TODO print 10 lines of the data to understand what type of text we are working with\n"]},{"cell_type":"markdown","metadata":{"id":"pWqVvz4x0t_G"},"source":["TODO: Understanding Regular\n","\n","Using the notation used in theory write regular expressions for\n","\n","\n","1. zero or more 'a'\n","2. one or more 'a'\n","1. starts with a and it is followed by zero or more b's\n","2. a sequence of one or more digits\n","2. two digits followed by a - followed by two digits\n","1. string of a's of odd length\n","2. string of a's of even length\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDJhBF85JwUs"},"outputs":[],"source":["# TODO: Run the following code comment what the program is doing\n","\n","import re\n","\n","my_text =  ''' \"aaa bbb abcd xyz\n","\n","123 4567\n","\n","\n","2   4 5 7 8 90\n","\n","Abc dEFG XYZ\n","\" '''\n","\n","# TODO: What are we searching for?\n","\n","my_regex=re.compile(r'([a-zA-Z][a-zA-Z])+')\n","\n","result=my_regex.findall(my_text)\n","\n","\n","\n","print(result)\n","\n","# TODO: What are we searching for?\n","\n","my_regex=re.compile(r'([A-Z][A-Z])+')\n","\n","result=my_regex.findall(my_text)\n","\n","print(result)\n","\n","# TODO: What are we searching for?\n","\n","my_regex=re.compile(r'([A-Z][A-Z]*)')\n","\n","result=my_regex.findall(my_text)\n","\n","print(result)\n","\n","\n","\n","# TODO: What is the difference with the above?\n","\n","result = re.search(r'([A-Z][A-Z]*)', my_text)\n","\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"Dpm1qvtjJMP1"},"source":["TODO: Take the tutorial  at [W3Schools on regular expressions in Python](https://www.w3schools.com/python/python_regex.asp)\n","and practice the code."]},{"cell_type":"markdown","metadata":{"id":"bfXmYXThJlNi"},"source":["TODO: Answer the following questions about RE in python\n","\n","\n","\n","1.  What is the purpose of the findall function\n","2.  What is the pupose of the search function\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dh6Tz0KTOowX"},"outputs":[],"source":["# TODO: examine item 95 of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBZpOMGJPk3n"},"outputs":[],"source":["# TODO: list sentences with string 2030 in the first 100 sentences of your data using a regular expression\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amGGdho6QT9x"},"outputs":[],"source":["# TODO: list sentences with string 2030 in the first 100 sentences of your data\n","# this time 2030 should be a full word not part of a word\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V1euKcIRRx-"},"outputs":[],"source":["# TODO:  find all sentences, within the first 100 sentences,  containing  a twitter hash tag '#' using regular expressions\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijoQCwsYctYe"},"outputs":[],"source":["# install library NLTK to  work with texts\n","!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7v1f7hMdC1g"},"outputs":[],"source":["# import stopwords and punctuation for English\n","import nltk\n","stops=nltk.download('stopwords')\n","punkt=nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3aHDvPamciXx"},"outputs":[],"source":["# word tokenization with nltk\n","\n","from nltk.tokenize import word_tokenize\n","text = \"Oh!!! I can't believe it is Friday.\"\n","print(word_tokenize(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZRkwjJddl_W"},"outputs":[],"source":["# TODO tokenizing text vs tokenizing tweets\n","from nltk.tokenize import TweetTokenizer\n","\n","# produce a tokenization using word_tokenize(...) and a tokenization using the tweet tokenizer ( TweetTokenizer() )\n","\n","# How are they different?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvqeoFnAfVo8"},"outputs":[],"source":["# TODO: what do you get if you tokenize item 95 of the data, show the tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVrJ6wzQRPs2"},"outputs":[],"source":["print(format(ord('â˜›'), '#08x'))\n","print(format(ord('â™€'), '#08x'))\n","print(format(ord('â™‚'), '#08x'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Co2_FitMhWRs"},"outputs":[],"source":["# TODO: using a regular expression list  the emojis â˜›   â™€  or â™‚  and the position in which the occur\n","# You should use the UNICODE representation of such emojis, which you can figure out checking a table or using\n","# print(format(ord(CHARACTER), '#08x'))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nav-_y5jb5sf"},"outputs":[],"source":["# TODO: extract all hashtags in first 100 sentences\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmRllXHWTSDj"},"outputs":[],"source":["# TODO: extract only the TAG of the hashtag in the first 100 sentences\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NdPPFQCf3EM"},"outputs":[],"source":["# TODO: list all hashtags which include a year (something that looks like YYYY)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WipAUhfUCT9"},"outputs":[],"source":["# TODO: for all hashtags including a year, extract the year"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05SpXJ5QoSlD"},"outputs":[],"source":["# TODO:  for all hashtags including a year, extract the year, list each year once"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"694J_vwO4IUF"},"outputs":[],"source":["# TODO: find all user mentions in the first 1000 sentences\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMV6Sbjv4mxL"},"outputs":[],"source":["# TODO: find all user mentions such that contain UPPERCASE letters only, in the first 1000 sentences\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ruZ9sM28tsQ"},"outputs":[],"source":["# TODO: find all strings containing the substring UN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLZ_qxcw9aRP"},"outputs":[],"source":["# TODO: find all strings containing the substring UN strictly in the middle of the token\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nx-d8JmW9t-K"},"outputs":[],"source":["# TODO: find all strings containing just numbers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ekoRz_y-CCu"},"outputs":[],"source":["# TODO: find all strings containing no numbers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s42UbWXEDTxI"},"outputs":[],"source":["# TODO: find any string between double quotes in the sentences\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQlNBZDSE_R5"},"outputs":[],"source":["# TODO: extract all urls in the 100 first sentences\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhi6l_M7HWR5"},"outputs":[],"source":["# TODO: extract all dates (can be DD/MM/YY or DD/MM/YYYY)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mguuUvi296x"},"outputs":[],"source":["# TODO: consider the following list of UNICODEs for emojis\n","emojis=['\\U0001F603', '\\U0001F604', '\\U0001F601', '\\U0001F606', '\\U0001F605', '\\U0001F923',\n","\t\t'\\U0001F602', '\\U0001F642', '\\U0001F643', '\\U0001F609', '\\U0001F60A', '\\U0001F607']\n","\n","# print them to understand what they are\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dydH4Gcl6hR6"},"outputs":[],"source":["# TODO: use regular expression to find and list any sentence containing at least one of the emojis above\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XnwDAHtXrFo"},"outputs":[],"source":["# TODO: use regular expressions to find and extract all ocurrences of  previous emojis and count how many of each\n","# list the results\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMvup0uQaMRb"},"outputs":[],"source":["# TODO: identify any sentences with 2 emojis in sequence such as ðŸ˜ŠðŸ˜Š\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNPXifHNZ6GSjU/wlbJ7DWU","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
