{"cells":[{"cell_type":"markdown","metadata":{"id":"4gHPcg59zjr6"},"source":["Theory of Computation 2023 - Horacio Saggion\n","\n","Deliverable Regular Expressions\n","\n","\n","Please indicate the full names and NIAs of the team members as well as the team number\n","\n","TEAM: #10\n","\n","MEMBERS:\n","\n","\t(253885) - Luca Franceschi\n","\t(253048) - Candela √Ålvarez L√≥pez\n","\t(254537) - Pau Ametller L√≥pez"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGcudUS8K4Jl"},"outputs":[],"source":["# If using Colaborate then allow Google to use your data files\n","\n","# CHANGE BEFORE DELIVERING\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YA1x6iboL-8o"},"outputs":[],"source":["# CHANGE BEFORE DELIVERING\n","# cd to the directory in drive you will use (change to your shared folder)\n","# %cd /content/drive/Shareddrives/ToC-2023/DELIVS/DELIV-1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_zqQQX_DMHx3"},"outputs":[],"source":["# reading some data using the pandas library\n","\n","# CHANGE BEFORE DELIVERING\n","# my_data=pd.read_csv('DATA/ToC_2023_REs.csv', sep=',')\n","my_data=pd.read_csv('ToC_2023_REs.csv', sep=',')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrZLazXSMs-r"},"outputs":[],"source":["# the data is from twitter so it will contain interesting content\n","# we only need the column 'text' to work with\n","\n","twitter_data=my_data['text']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qgurvr6NA7W"},"outputs":[],"source":["# TODO print 10 lines of the data to understand what type of text we are working with\n","\n","display(twitter_data.head(10))"]},{"cell_type":"markdown","metadata":{"id":"pWqVvz4x0t_G"},"source":["TODO: Understanding Regular\n","\n","Using the notation used in theory write regular expressions for\n","\n","\n","1. zero or more 'a'\n","2. one or more 'a'\n","1. starts with a and it is followed by zero or more b's\n","2. a sequence of one or more digits\n","2. two digits followed by a - followed by two digits\n","1. string of a's of odd length\n","2. string of a's of even length\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDJhBF85JwUs"},"outputs":[],"source":["# TODO: Run the following code comment what the program is doing\n","\n","my_text =  ''' \"aaa bbb abcd xyz\n","\n","123 4567\n","\n","\n","2   4 5 7 8 90\n","\n","Abc dEFG XYZ\n","\" '''\n","\n","# TODO: What are we searching for?\n","# Any even combination of uppercase or lowercase characters not including the empty string.\n","\n","my_regex=re.compile(r'([a-zA-Z][a-zA-Z])+')\n","result=my_regex.findall(my_text)\n","\n","print(result)\n","\n","# TODO: What are we searching for?\n","# Any even combination of uppercase letters not including the empty string.\n","\n","my_regex=re.compile(r'([A-Z][A-Z])+')\n","result=my_regex.findall(my_text)\n","\n","print(result)\n","\n","# TODO: What are we searching for?\n","# Any combination of uppercase letters not including the empty string (basically [A-Z]+).\n","\n","my_regex=re.compile(r'([A-Z][A-Z]*)')\n","result=my_regex.findall(my_text)\n","\n","print(result)\n","\n","# TODO: What is the difference with the above?\n","# In this case it only shows first match or none, while in the above cases it matched all ocurrences of the regular expression\n","\n","result = re.search(r'([A-Z][A-Z]*)', my_text)\n","\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"Dpm1qvtjJMP1"},"source":["TODO: Take the tutorial  at [W3Schools on regular expressions in Python](https://www.w3schools.com/python/python_regex.asp)\n","and practice the code."]},{"cell_type":"markdown","metadata":{"id":"bfXmYXThJlNi"},"source":["TODO: Answer the following questions about RE in python\n","\n","\n","\n","1.  What is the purpose of the findall function\n","\n","    Purpose of findall: filter a text and getting only the parts that are meaningful using regular expressions.\n","2.  What is the pupose of the search function\n","\n","    Purpose of search: find if there is a matching expresion or if there is none for that regular expression.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dh6Tz0KTOowX"},"outputs":[],"source":["# TODO: examine item 95 of the data\n","\n","twitter_data.loc[95]"]},{"cell_type":"markdown","metadata":{},"source":["We observe that the item contained is a tweet. In this case composed of some mentions, hashtags, links and text."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBZpOMGJPk3n"},"outputs":[],"source":["# TODO: list sentences with string 2030 in the first 100 sentences of your data using a regular expression\n","\n","my_regex = re.compile(r'2030')\n","found_sentences = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.search(item)\n","    if result != None:\n","        found_sentences.append(item) #Append the entire sentence\n","\n","print('We have found the following %d matches:\\n' % len(found_sentences))\n","for sentence in found_sentences: print(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amGGdho6QT9x"},"outputs":[],"source":["# TODO: list sentences with string 2030 in the first 100 sentences of your data\n","# this time 2030 should be a full word not part of a word\n","\n","my_regex = re.compile(r'\\b2030\\b')\n","found_sentences = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.search(item)\n","    if result != None:\n","        found_sentences.append(item) #Append the entire sentence\n","\n","print('We have found the following %d matches:\\n' % len(found_sentences))\n","for sentence in found_sentences: print(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V1euKcIRRx-"},"outputs":[],"source":["# TODO:  find all sentences, within the first 100 sentences,  containing a twitter hash tag '#' using regular expressions\n","\n","my_regex = re.compile(r'#')\n","found_sentences = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.search(item)\n","    if result != None:\n","        found_sentences.append(item) #Append the entire sentence\n","        \n","print('We have found the following %d matches:\\n' % len(found_sentences))\n","for sentence in found_sentences: print(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijoQCwsYctYe"},"outputs":[],"source":["# install library NLTK to  work with texts\n","\n","# CHANGE BEFORE DELIVERING\n","# !pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","from nltk import word_tokenize, TweetTokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7v1f7hMdC1g"},"outputs":[],"source":["# import stopwords and punctuation for English\n","\n","stops=nltk.download('stopwords')\n","punkt=nltk.download('punkt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3aHDvPamciXx"},"outputs":[],"source":["# word tokenization with nltk\n","\n","text = \"Oh!!! I can't believe it is Friday.\"\n","print(word_tokenize(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rZRkwjJddl_W"},"outputs":[],"source":["# TODO tokenizing text vs tokenizing tweets\n","# produce a tokenization using word_tokenize(...) and a tokenization using the tweet tokenizer ( TweetTokenizer() )\n","\n","tweet_tokenizer = TweetTokenizer()\n","print(twitter_data.loc[1]) #Normal text\n","print(word_tokenize(twitter_data.loc[1])) #Word tokenized text\n","print(tweet_tokenizer.tokenize(twitter_data.loc[1])) #Tweet tokenized text"]},{"cell_type":"markdown","metadata":{},"source":["How are they different?\n","The Word tokenize splits all found_symbols while twitter tokenize keeps mentions, hashtag, abbreviations and links together as one element. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvqeoFnAfVo8"},"outputs":[],"source":["# TODO: what do you get if you tokenize item 95 of the data, show the tokens\n","\n","print(word_tokenize(twitter_data.loc[95]))\n","print(tweet_tokenizer.tokenize(twitter_data.loc[95]))"]},{"cell_type":"markdown","metadata":{},"source":["What we get when we word tokenize item 95 is that it once again separates found_symbols such as # and @ yet it does not separate emojis (wrongly), meanwhile twitter tokenizes emojis but does not separate hashtags, mentions, abbreviations nor links."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVrJ6wzQRPs2"},"outputs":[],"source":["print(format(ord('‚òõ'), '#08x'))\n","print(format(ord('‚ôÄ'), '#08x'))\n","print(format(ord('‚ôÇ'), '#08x'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Co2_FitMhWRs"},"outputs":[],"source":["# TODO: using a regular expression list  the emojis ‚òõ   ‚ôÄ  or ‚ôÇ  and the position in which they occur\n","# You should use the UNICODE representation of such emojis, which you can figure out checking a table or using\n","# print(format(ord(CHARACTER), '#08x'))\n","counter = 0\n","found_symbols = {\n","\t'‚òõ': [],\n","\t'‚ôÄ': [],\n","\t'‚ôÇ': []\n","}\n","\n","my_regex = re.compile(r'\\u261b|\\u2640|\\u2642')\n","\n","for item in twitter_data:\n","\tfor i in my_regex.finditer(item):\n","\t\tfound_symbols[i.group()].append(i.start())\n","\t\tcounter += 1\n","\n","print('We have found the following %d matches:\\n' % counter)\n","for key in found_symbols: print(f'{len(found_symbols[key])}\\tmatches of {key} in positions: {found_symbols[key]}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nav-_y5jb5sf"},"outputs":[],"source":["# TODO: extract all hashtags in first 100 sentences\n","\n","my_regex = re.compile(r'#\\w+') #Returns a match where the string contains a hash and any word characters (a to Z, 0-9, _)\n","found_hashtags = []\n","\n","for item in twitter_data.head(100):\n","\tresult = my_regex.findall(item)\n","\tfor e in result:\n","\t\tfound_hashtags.append(e) #Append the part of the string where there was a match\n","\n","print('We have found the following %d matches:\\n' % len(found_hashtags))\n","for hashtag in found_hashtags: print(hashtag)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmRllXHWTSDj"},"outputs":[],"source":["# TODO: extract only the TAG of the hashtag in the first 100 sentences\n","\n","my_regex = re.compile(r'#(\\w+)') #Make a group without the hash\n","found_tags = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_tags.append(e) #Append the part of the string where there was a match\n","\n","print('We have found the following %d matches:\\n' % len(found_tags))\n","for tag in found_tags: print(tag)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5NdPPFQCf3EM"},"outputs":[],"source":["# TODO: list all hashtags which include a year (something that looks like YYYY)\n","\n","my_regex = re.compile(r'#[a-zA-Z]*[0-9]{4}[a-zA-Z]*') \n","#Combination of a hash plus any number of letters, four digits between 0 and 9, and any number of letters again\n","found_hashtags = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_hashtags.append(e) #Append the part of the string where there was a match\n","\n","print('We have found the following %d matches:\\n' % len(found_hashtags))\n","for hashtag in found_hashtags: print(hashtag)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WipAUhfUCT9"},"outputs":[],"source":["# TODO: for all hashtags including a year, extract the year\n","\n","my_regex = re.compile(r'#[a-zA-Z]*([0-9]{4})[a-zA-Z]*')\n","#Combination of a hash plus any number of letters, four digits between 0 and 9, and any number of letters again \n","#Yet we group the digits with () for it to only append this matched part\n","found_years = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_years.append(e) #Append the part of the string where there was a match\n","\n","print('We have found the following %d matches:\\n' % len(found_years))\n","for year in found_years: print(year)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05SpXJ5QoSlD"},"outputs":[],"source":["# TODO:  for all hashtags including a year, extract the year, list each year once\n","\n","my_regex = re.compile(r'#[a-zA-Z]*([0-9]{4})[a-zA-Z]*')\n","found_years_set = set() #A set does not allow repetition\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_years_set.add(e)\n","\n","print('We have found the following %d distinct matches:\\n' % len(found_years_set))\n","for year in found_years_set: print(year)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"694J_vwO4IUF"},"outputs":[],"source":["# TODO: find all user mentions in the first 1000 sentences\n","\n","my_regex = re.compile(r'@\\w+') #Returns a match where the string contains an @ and any word characters (a to Z, 0-9, _)\n","found_mentions = []\n","\n","for item in twitter_data.head(1000):\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_mentions.append(e)\n","        \n","print('We have found the following %d matches:\\n' % len(found_mentions))\n","for mention in found_mentions: print(mention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMV6Sbjv4mxL"},"outputs":[],"source":["# TODO: find all user mentions such that contain UPPERCASE letters only, in the first 1000 sentences\n","\n","my_regex = re.compile(r'(@[A-Z]+)\\b') #Return a match where the string contains an @ and ends with a combination of capital letters \n","found_mentions = []\n","\n","for item in twitter_data.head(1000):\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_mentions.append(e)\n","        \n","print('We have found the following %d matches:\\n' % len(found_mentions))\n","for mention in found_mentions: print(mention)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ruZ9sM28tsQ"},"outputs":[],"source":["# TODO: find all strings containing the substring UN\n","\n","my_regex = re.compile(r'(\\S*UN\\S*)\\b')\n","#Return a match where the string may contain any combination of characters or white space before and after the UN substring\n","found_strings = []\n","\n","for item in twitter_data:\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_strings.append(e)\n","\n","print('We have found the following %d matches:\\n' % len(found_strings))\n","for string in found_strings: print(string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLZ_qxcw9aRP"},"outputs":[],"source":["# TODO: find all strings containing the substring UN strictly in the middle of the token\n","\n","my_regex = re.compile(r'(\\S+UN\\S+)\\b') \n","#Return a match where the string contains any combination of characters before and after the UN substring never a white space\n","found_strings = []\n","\n","for item in twitter_data:\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_strings.append(e)\n","        \n","print('We have found the following %d matches:\\n' % len(found_strings))\n","for string in found_strings: print(string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nx-d8JmW9t-K"},"outputs":[],"source":["# TODO: find all strings containing just numbers\n","\n","my_regex = re.compile(r'\\b(\\d+)\\b') #Returns a match where the string contains digits and starts and ends with them\n","found_strings = []\n","\n","for item in twitter_data:\n","    result = my_regex.findall(item)\n","    for e in result:\n","        found_strings.append(int(e))\n","        \n","print('We have found the following %d matches:\\n' % len(found_strings))\n","for string in found_strings: print(string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ekoRz_y-CCu"},"outputs":[],"source":["# TODO: find all strings containing no numbers\n","\n","\n","\n","#FIX REGULAR EXPRESSION\n","\n","\n","\n","#my_regex = re.compile(r'\\b([^\\d\\s]+)\\b') #Returns a match where the string does not contain digits (but it gives problems with puntuation signs)\n","my_regex = re.compile(r'\\D\\S+')\n","found_strings = []\n","\n","for item in twitter_data.head(100):\n","   result = my_regex.findall(item)\n","   for e in result:\n","       found_strings.append(e)\n","\n","print('We have found the following %d matches:\\n' % len(found_strings))\n","for string in found_strings: print(string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s42UbWXEDTxI"},"outputs":[],"source":["# TODO: find any string between double quotes in the sentences\n","\n","my_regex = re.compile(r'(\")([^\"]*)(\")') #Return match where the string has double quotes and inside may contain more quotes\n","\n","found_strings = []\n","\n","for item in twitter_data:\n","\tfor i in my_regex.finditer(item):\n","\t\tfound_strings.append(i.group(2))\n","\n","print('We have found the following %d matches:\\n' % len(found_strings))\n","for string in found_strings: print(string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQlNBZDSE_R5"},"outputs":[],"source":["# TODO: extract all urls in the 100 first sentences\n","\n","my_regex = re.compile(r'\\b(http[s]?://\\S+)') #Return match where the string starts with http:// or https://\n","found_urls = []\n","\n","for item in twitter_data.head(100):\n","    result = my_regex.findall(item)\n","    for element in result:\n","        found_urls.append(element) #Append the part of the string where there was a match\n","        \n","print('We have found the following %d matches:\\n' % len(found_urls))\n","for url in found_urls: print(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nhi6l_M7HWR5"},"outputs":[],"source":["# TODO: extract all dates (can be DD/MM/YY or DD/MM/YYYY)\n","\n","my_regex = re.compile(r'([0-2][0-9]|[3][0-1])/([0][1-9]|[1][0-2])/\\d{2,4}') #Return match where the string matches this combination of numbers\n","found_dates = []\n","\n","for item in twitter_data:\n","    result = my_regex.finditer(item)\n","    for element in result:\n","        found_dates.append(element.group()) #Append the part of the string where there was a match\n","        \n","print('We have found the following %d matches:\\n' % len(found_dates))\n","for date in found_dates: print(date)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mguuUvi296x"},"outputs":[],"source":["# TODO: consider the following list of UNICODEs for emojis\n","emojis=['\\U0001F603', '\\U0001F604', '\\U0001F601', '\\U0001F606', '\\U0001F605', '\\U0001F923',\n","\t\t'\\U0001F602', '\\U0001F642', '\\U0001F643', '\\U0001F609', '\\U0001F60A', '\\U0001F607']\n","\n","# print them to understand what they are\n","print(emojis)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dydH4Gcl6hR6"},"outputs":[],"source":["# TODO: use regular expression to find and list any sentence containing at least one of the emojis above\n","\n","my_regex = re.compile(r'\\U0001F603|\\U0001F604|\\U0001F601|\\U0001F606|\\U0001F605|\\U0001F923|\\U0001F602|\\U0001F642|\\U0001F643|\\U0001F609|\\U0001F60A|\\U0001F607')\n","found_sentences = []\n","\n","for item in twitter_data:\n","    result = my_regex.search(item)\n","    if result != None:\n","        found_sentences.append(item) #Append the entire sentence\n","        \n","print('We have found the following %d matches:\\n' % len(found_sentences))\n","for sentence in found_sentences: print(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XnwDAHtXrFo"},"outputs":[],"source":["# TODO: use regular expressions to find and extract all ocurrences of previous emojis and count how many of each\n","# list the results\n","\n","counter = 0\n","found_emojis = {}\n","\n","my_regex = re.compile(r'\\U0001F603|\\U0001F604|\\U0001F601|\\U0001F606|\\U0001F605|\\U0001F923|\\U0001F602|\\U0001F642|\\U0001F643|\\U0001F609|\\U0001F60A|\\U0001F607')\n","\n","for item in twitter_data:\n","    for element in my_regex.finditer(item):\n","        if element.group() not in found_emojis:\n","            found_emojis[element.group()] = 1\n","        else:\n","            found_emojis[element.group()] += 1\n","        counter += 1\n","        \n","print('We have found the following %d matches:\\n' % counter)\n","for key in found_emojis: print(f'{found_emojis[key]}\\tmatches of {key}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMvup0uQaMRb"},"outputs":[],"source":["# TODO: identify any sentences with 2 emojis in sequence such as üòäüòä\n","\n","\n","\n","#REVISAR LO QUE PRINTEA, ES UN ERROR ESOS HASHTAGS, URLS?\n","\n","\n","\n","\n","my_regex = re.compile(r'(\\U0001F603|\\U0001F604|\\U0001F601|\\U0001F606|\\U0001F605|\\U0001F923|\\U0001F602|\\U0001F642|\\U0001F643|\\U0001F609|\\U0001F60A|\\U0001F607){2}')\n","\n","found_sentences_emojis = []\n","\n","for item in twitter_data:\n","    result = my_regex.search(item)\n","    if result != None:\n","        found_sentences_emojis.append(item) #Append the entire sentence\n","        \n","print('We have found the following %d matches:\\n' % len(found_sentences_emojis))\n","for sentence_emoji in found_sentences_emojis: print(sentence_emoji)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNPXifHNZ6GSjU/wlbJ7DWU","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
